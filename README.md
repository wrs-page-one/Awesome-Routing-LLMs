# Awesome-Routing-LLMs
A curated list of awesome works in Routing LLMs paradigm

ðŸ¤©ðŸ‘‰ Welcome to submit your contributions to this code repository.


## Routing LLM Paper (preprint)

| **Paper**                                                                                             | **Conference/Journal** |**Code**    |**Type**    |
|--------------------------------------------------------------------------------------------------------|------------------------|--------------------|------------|
| [RouterEval: A Comprehensive Benchmark for Routing LLMs to Explore Model-level Scaling Up in LLMs](https://arxiv.org/pdf/2503.10657)          | arxiv'25               |   [Link](https://github.com/MilkThink-Lab/RouterEval)    | Benchmark |
| [Universal Model Routing for Efficient LLM Inference](https://arxiv.org/pdf/2502.08773)                                        | arxiv'25               |   -    |  Method |
| [Prompt-to-Leaderboard](https://arxiv.org/pdf/2502.14855)                                   | arxiv'25            | [Link](https://github.com/lmarena/p2l)      | Method |
| [MixLLM: Dynamic Routing in Mixed Large Language Models](https://arxiv.org/pdf/2502.18482)                                   | arxiv'25            |-     | Method |
| [MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs](https://arxiv.org/abs/2407.10834)                                   | arxiv'24            |-     | Method |
| [Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models](https://arxiv.org/abs/2407.06089)                                   | arxiv'24            |-     | Survey |
| [Routoo: Learning to Route to Large Language Models Effectively](https://arxiv.org/abs/2401.13979)                                   | arxiv'24            |-     | Method |
| [Tryage: Real-time, intelligent Routing of User Prompts to Large Language Models ](https://arxiv.org/abs/2308.11601)                                   | arxiv'23            |-     | Method |
| [FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance](https://arxiv.org/abs/2305.05176)                                   | arxiv'23           | [Link](https://github.com/stanford-futuredata/FrugalGPT)      | Method |








## Routing LLM Paper
| **Paper**                                                                                             | **Conference/Journal** |**Code**    |**Type**    |
|--------------------------------------------------------------------------------------------------------|------------------------|--------------------|------------|
|  [Capability Instruction Tuning: A New Paradigm for Dynamic LLM Routing](https://arxiv.org/abs/2502.17282)                                | AAAI'25             | [Link](https://github.com/Now-Join-Us/CIT-LLM-Routing)      | Method |
| [EmbedLLM: Learning Compact Representations of Large Language Models](https://openreview.net/forum?id=Fs9EabmQrJ)                                        | ICLR'25               |  [Link](https://github.com/richardzhuang0412/EmbedLLM)     | Method |
| [RouteLLM: Learning to Route LLMs from Preference Data](https://openreview.net/forum?id=8sSqNntaMr)                                        | ICLR'25               |  [Link](https://github.com/lm-sys/RouteLLM)     | Method |
| [Cache & Distil: Optimising API Calls to Large Language Models](https://aclanthology.org/2024.findings-acl.704/)                                   | ACL'24            | -     | Method |
| [Model-GLUE: Democratized LLM Scaling for A Large Model Zoo in the Wild](https://arxiv.org/pdf/2410.05357)                                   | NeurIPS'24            | [Link](https://github.com/Model-GLUE/Model-GLUE/tree/main)      | Method |
| [AutoMix: Automatically Mixing Language Models](https://arxiv.org/abs/2310.12963)                                   | NeurIPS'24            | [Link](https://github.com/automix-llm/automix)      | Method |
|  [Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models](https://aclanthology.org/2024.naacl-long.109/)                                | NAACL'24             |  -     | Method |
|  [Harnessing the Power of Multiple Minds: Lessons Learned from LLM Routing](https://arxiv.org/pdf/2405.00467)                                | NAACLW'24             | [Link](https://github.com/kvadityasrivatsa/llm-routing)      | Method |
| [Large Language Model Routing with Benchmark Datasets](https://arxiv.org/pdf/2309.15789)                                        | COLM'24               |   -    | Method |
| [Optimising Calls to Large Language Models with Uncertainty-Based Two-Tier Selection](https://arxiv.org/abs/2405.02134)                                        | COLM'24               |   [Link](https://github.com/guillemram97/margin_llms)     | Method |
| [OptLLM: Optimal Assignment of Queries to Large Language Models](https://arxiv.org/abs/2405.15130)                                        | ICWS'24               |   [Link](https://github.com/superyue72/OptLLM)     | Method |
| [RouterBench: A Benchmark for Multi-LLM Routing System](https://openreview.net/forum?id=IVXmV8Uxwh)                                   | ICMLW'24            | [Link](https://github.com/withmartian/routerbench)      | Benchmark |
| [Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling](https://dl.acm.org/doi/10.1145/3616855.3635825)                                        | WSDM'24               |   [Link](https://github.com/epfl-dlab/forc)     | Method |
| [Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing](https://arxiv.org/abs/2404.14618)                                        | ICLR'24               |  -     | Method |
|  [Model Spider: Learning to Rank Pre-Trained Models Efficiently](https://openreview.net/pdf?id=exg62lfHrB)                                | NeurIPS'23             | [Link](https://github.com/zhangyikaii/Model-Spider)      | Method |
| [LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion](https://arxiv.org/abs/2306.02561)                                   | ACL'23           | [Link](https://yuchenlin.xyz/LLM-Blender/)      | Method |


